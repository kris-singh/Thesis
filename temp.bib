@article{zhangdiversified,
  title={Diversified Mini-Batch Sampling using Repulsive Point Processes},
  author={Zhang, Cheng and {\"O}ztireli, Cengiz and Mandt, Stephan}
}
@article{wang2017accelerating,
  title={Accelerating deep neural network training with inconsistent stochastic gradient descent},
  author={Wang, Linnan and Yang, Yi and Min, Renqiang and Chakradhar, Srimat},
  journal={Neural Networks},
  volume={93},
  pages={219--229},
  year={2017},
  publisher={Elsevier}
}
@article{zhao2014accelerating,
  title={Accelerating minibatch stochastic gradient descent using stratified sampling},
  author={Zhao, Peilin and Zhang, Tong},
  journal={arXiv preprint arXiv:1405.3080},
  year={2014}
}
@inproceedings{chang2017active,
  title={Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples},
  author={Chang, Haw-Shiuan and Learned-Miller, Erik and McCallum, Andrew},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1003--1013},
  year={2017}
}
@article{gao2015active,
  title={Active Sampler: Light-weight Accelerator for Complex Data Analytics at Scale},
  author={Gao, Jinyang and Jagadish, HV and Ooi, Beng Chin},
  journal={arXiv preprint arXiv:1512.03880},
  year={2015}
}
@article{chakraborty2015adaptive,
  title={Adaptive batch mode active learning},
  author={Chakraborty, Shayok and Balasubramanian, Vineeth and Panchanathan, Sethuraman},
  journal={IEEE transactions on neural networks and learning systems},
  volume={26},
  number={8},
  pages={1747--1760},
  year={2015},
  publisher={IEEE}
}
@inproceedings{gopal2016adaptive,
  title={Adaptive sampling for SGD by exploiting side information},
  author={Gopal, Siddharth},
  booktitle={International Conference on Machine Learning},
  pages={364--372},
  year={2016}
}
@article{golovin2011adaptive,
  title={Adaptive submodularity: Theory and applications in active learning and stochastic optimization},
  author={Golovin, Daniel and Krause, Andreas},
  journal={Journal of Artificial Intelligence Research},
  volume={42},
  pages={427--486},
  year={2011}
}
@article{im2016empirical,
  title={An Empirical Analysis of Deep Network Loss Surfaces},
  author={Im, Daniel Jiwoong and Tao, Michael and Branson, Kristin},
  journal={arXiv preprint arXiv:1612.04010},
  year={2016}
}
@article{stich2017approximate,
  title={Approximate steepest coordinate descent},
  author={Stich, Sebastian U and Raj, Anant and Jaggi, Martin},
  journal={arXiv preprint arXiv:1706.08427},
  year={2017}
}
@article{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1704.03003},
  year={2017}
}
@inproceedings{svetlik2017automatic,
  title={Automatic Curriculum Graph Generation for Reinforcement Learning Agents.},
  author={Svetlik, Maxwell and Leonetti, Matteo and Sinapov, Jivko and Shah, Rishi and Walker, Nick and Stone, Peter},
  booktitle={AAAI},
  pages={2590--2596},
  year={2017}
}
@article{katharopoulos2017biased,
  title={Biased Importance Sampling for Deep Neural Network Training},
  author={Katharopoulos, Angelos and Fleuret, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1706.00043},
  year={2017}
}
@article{de2016big,
  title={Big Batch SGD: Automated Inference using Adaptive Batch Sizes},
  author={De, Soham and Yadav, Abhay and Jacobs, David and Goldstein, Tom},
  journal={arXiv preprint arXiv:1610.05792},
  year={2016}
}
@article{liu2016black,
  title={Black-box importance sampling},
  author={Liu, Qiang and Lee, Jason D},
  journal={arXiv preprint arXiv:1610.05247},
  year={2016}
}
@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009},
  organization={ACM}
}
@article{balles2016coupling,
  title={Coupling adaptive batch sizes with learning rates},
  author={Balles, Lukas and Romero, Javier and Hennig, Philipp},
  journal={arXiv preprint arXiv:1612.05086},
  year={2016}
}
@article{bilmes2017deep,
  title={Deep Submodular Functions},
  author={Bilmes, Jeffrey and Bai, Wenruo},
  journal={arXiv preprint arXiv:1701.08939},
  year={2017}
}
@inproceedings{zhang2017determinantal,
  title={Determinantal point processes for mini-batch diversification},
  author={Zhang, Cheng and Kjellstr{\"o}m, Hedvig and Mandt, Stephan},
  booktitle={33rd Conference on Uncertainty in Artificial Intelligence, UAI 2017, Sydney, Australia, 11 August 2017 through 15 August 2017},
  year={2017},
  organization={AUAI Press Corvallis}
}
@article{smith2017don,
  title={Don't Decay the Learning Rate, Increase the Batch Size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Le, Quoc V},
  journal={arXiv preprint arXiv:1711.00489},
  year={2017}
}
@article{nesterov2012efficiency,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}
@article{sagun2016eigenvalues,
  title={Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond},
  author={Sagun, Levent and Bottou, L{\'e}on and LeCun, Yann},
  journal={arXiv preprint arXiv:1611.07476},
  year={2016}
}
@article{chaudhari2016entropy,
  title={Entropy-sgd: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann},
  journal={arXiv preprint arXiv:1611.01838},
  year={2016}
}
@article{perekrestenko2017faster,
  title={Faster coordinate descent via adaptive importance sampling},
  author={Perekrestenko, Dmytro and Cevher, Volkan and Jaggi, Martin},
  journal={arXiv preprint arXiv:1703.02518},
  year={2017}
}
@inproceedings{golovin2010adaptive,
  title={Adaptive Submodularity: A New Approach to Active Learning and Stochastic Optimization.},
  author={Golovin, Daniel and Krause, Andreas},
  booktitle={COLT},
  pages={333--345},
  year={2010}
}
@inproceedings{hassani2017gradient,
  title={Gradient methods for submodular maximization},
  author={Hassani, Hamed and Soltanolkotabi, Mahdi and Karbasi, Amin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5843--5853},
  year={2017}
}
@article{fan2017learning,
  title={Learning What Data to Learn},
  author={Fan, Yang and Tian, Fei and Qin, Tao and Bian, Jiang and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1702.08635},
  year={2017}
}
@article{loshchilov2015online,
  title={Online batch selection for faster training of neural networks},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1511.06343},
  year={2015}
}
@article{robinson2008new,
  title={New benchmarks in higher education: Student engagement in online learning},
  author={Robinson, Chin Choo and Hullinger, Hallett},
  journal={Journal of Education for Business},
  volume={84},
  number={2},
  pages={101--109},
  year={2008},
  publisher={Taylor \& Francis}
}
@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}
@inproceedings{lamb2016professor,
  title={Professor forcing: A new algorithm for training recurrent networks},
  author={Lamb, Alex M and GOYAL, Anirudh Goyal ALIAS PARTH and Zhang, Ying and Zhang, Saizheng and Courville, Aaron C and Bengio, Yoshua},
  booktitle={Advances In Neural Information Processing Systems},
  pages={4601--4609},
  year={2016}
}
@inproceedings{stich2017safe,
  title={Safe Adaptive Importance Sampling},
  author={Stich, Sebastian U and Raj, Anant and Jaggi, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4384--4394},
  year={2017}
}
@article{gao2016sample,
  title={Sample Importance in Training Deep Neural Networks},
  author={Gao, Tianxiang and Jojic, Vladimir},
  year={2016}
}
@article{kim2018screenernet,
  title={ScreenerNet: Learning Curriculum for Neural Networks},
  author={Kim, Tae-Hoon and Choi, Jonghyun},
  journal={arXiv preprint arXiv:1801.00904},
  year={2018}
}
@inproceedings{zhao2015stochastic,
  title={Stochastic optimization with importance sampling for regularized loss minimization},
  author={Zhao, Peilin and Zhang, Tong},
  booktitle={international conference on machine learning},
  pages={1--9},
  year={2015}
}
@article{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  journal={arXiv preprint arXiv:1703.04730},
  year={2017}
}
@article{alain2015variance,
  title={Variance reduction in SGD by distributed importance sampling},
  author={Alain, Guillaume and Lamb, Alex and Sankar, Chinnadhurai and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1511.06481},
  year={2015}
}
@inproceedings{wei2015submodularity,
  title={Submodularity in data subset selection and active learning},
  author={Wei, Kai and Iyer, Rishabh and Bilmes, Jeff},
  booktitle={International Conference on Machine Learning},
  pages={1954--1963},
  year={2015}
}
@inproceedings{gotovos2015sampling,
  title={Sampling from probabilistic submodular models},
  author={Gotovos, Alkis and Hassani, Hamed and Krause, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1945--1953},
  year={2015}
}
@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM Journal on Control and Optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}
@book{nesterov2013introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@article{schmidt2013minimizing,
  title={Minimizing Finite Sums with the Stochastic Average Gradient. arXiv. org},
  author={Schmidt, M and Le Roux, N and Bach, F},
  year={2013}
}
@inproceedings{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={Advances in neural information processing systems},
  pages={315--323},
  year={2013}
}
@article{xu2009submodular,
  title={Submodular utility optimization in sensor networks for capacity constraints},
  author={Xu, You and Chen, Yixin and Lu, Chenyang and Bhattacharya, Sangeeta and Saifullah, Abu},
  year={2009}
}
@inproceedings{das2008algorithms,
  title={Algorithms for subset selection in linear regression},
  author={Das, Abhimanyu and Kempe, David},
  booktitle={Proceedings of the fortieth annual ACM symposium on Theory of computing},
  pages={45--54},
  year={2008},
  organization={ACM}
}
@article{nemhauser,
  title={An analysis of approximations for maximizing submodular set functions—I},
  author={Nemhauser, George L and Wolsey, Laurence A and Fisher, Marshall L},
  journal={Mathematical Programming},
  volume={14},
  number={1},
  pages={265--294},
  year={1978},
  publisher={Springer}
}
@inproceedings{schaul2013no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  booktitle={International Conference on Machine Learning},
  pages={343--351},
  year={2013}
}
@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}
@article{devarakonda2017adabatch,
  title={AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks},
  author={Devarakonda, Aditya and Naumov, Maxim and Garland, Michael},
  journal={arXiv preprint arXiv:1712.02029},
  year={2017}
}

@inproceedings{wang2013variance,
  title={Variance reduction for stochastic gradient optimization},
  author={Wang, Chong and Chen, Xi and Smola, Alexander J and Xing, Eric P},
  booktitle={Advances in Neural Information Processing Systems},
  pages={181--189},
  year={2013}
}
@article{bouchard2015accelerating,
  title={Accelerating stochastic gradient descent via online learning to sample},
  author={Bouchard, Guillaume and Trouillon, Th{\'e}o and Perez, Julien and Gaidon, Adrien},
  journal={arXiv preprint arXiv:1506.09016},
  year={2015}
}
@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}
@inproceedings{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  booktitle={NIPS workshop on deep learning and unsupervised feature learning},
  volume={2011},
  number={2},
  pages={5},
  year={2011}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  publisher={Citeseer}
}
@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}
@article{zaremba2014recurrent,
  title={Recurrent neural network regularization},
  author={Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1409.2329},
  year={2014}
}
@inproceedings{tschiatschek2016learning,
  title={Learning Probabilistic Submodular Diversity Models Via Noise Contrastive Estimation.},
  author={Tschiatschek, Sebastian and Djolonga, Josip and Krause, Andreas},
  booktitle={AISTATS},
  pages={770--779},
  year={2016}
}
@inproceedings{shrivastava2016training,
  title={Training region-based object detectors with online hard example mining},
  author={Shrivastava, Abhinav and Gupta, Abhinav and Girshick, Ross},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={761--769},
  year={2016}
}
@inproceedings{mirzasoleiman2015lazier,
  title={Lazier Than Lazy Greedy.},
  author={Mirzasoleiman, Baharan and Badanidiyuru, Ashwinkumar and Karbasi, Amin and Vondr{\'a}k, Jan and Krause, Andreas},
  booktitle={AAAI},
  pages={1812--1818},
  year={2015}
}
@article{tschiatschek2018differentiable,
  title={Differentiable Submodular Maximization},
  author={Tschiatschek, Sebastian and Sahin, Aytunc and Krause, Andreas},
  journal={arXiv preprint arXiv:1803.01785},
  year={2018}
}
@inproceedings{badanidiyuru2014fast,
  title={Fast algorithms for maximizing submodular functions},
  author={Badanidiyuru, Ashwinkumar and Vondr{\'a}k, Jan},
  booktitle={Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms},
  pages={1497--1514},
  year={2014},
  organization={Society for Industrial and Applied Mathematics}
}
@inproceedings{ashkan2015optimal,
  title={Optimal Greedy Diversity for Recommendation.},
  author={Ashkan, Azin and Kveton, Branislav and Berkovsky, Shlomo and Wen, Zheng},
  booktitle={IJCAI},
  pages={1742--1748},
  year={2015}
}
@article{krause2008near,
  title={Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies},
  author={Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={Feb},
  pages={235--284},
  year={2008}
}
@incollection{minoux1978accelerated,
  title={Accelerated greedy algorithms for maximizing submodular set functions},
  author={Minoux, Michel},
  booktitle={Optimization techniques},
  pages={234--243},
  year={1978},
  publisher={Springer}
}
@inproceedings{ashkan2015optimal,
  title={Optimal Greedy Diversity for Recommendation.},
  author={Ashkan, Azin and Kveton, Branislav and Berkovsky, Shlomo and Wen, Zheng},
  booktitle={IJCAI},
  pages={1742--1748},
  year={2015}
}